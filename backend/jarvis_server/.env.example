# J.A.R.V.I.S Server Configuration
# Copy this file to .env and configure

# ===========================================
# LOCAL MODEL SETTINGS (LM Studio / Ollama)
# ===========================================
# Set to "true" to use local model instead of OpenAI
USE_LOCAL_MODEL=true

# LM Studio runs on port 1234 by default
# Ollama runs on port 11434
OPENAI_BASE_URL=http://localhost:1234/v1

# ===========================================
# OPENAI SETTINGS (if USE_LOCAL_MODEL=false)
# ===========================================
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# ===========================================
# OPTIONAL SETTINGS
# ===========================================
# OpenWeatherMap API Key (for weather queries)
OPENWEATHER_API_KEY=your_openweather_api_key_here

# Server Configuration
PORT=8000
HOST=0.0.0.0

# Model Configuration
MODEL=gpt-4o-mini
MAX_TOKENS=500
TEMPERATURE=0.7
